# Feedback sobre as Perguntas de Avaliação de Modelos de Machine Learning

1. **O que é a matriz de confusão?**  
   **Resposta correta:** B  
   **Feedback:** A matriz de confusão é uma ferramenta essencial na avaliação de modelos de classificação. Ela permite visualizar o desempenho do modelo ao exibir as predições corretas e incorretas para cada classe. Esta pergunta aborda o conceito básico e é importante para assegurar que o aluno compreenda a estrutura fundamental para análise de erros em classificadores.

2. **Qual das seguintes métricas é mais adequada para avaliar modelos em conjuntos de dados desbalanceados?**  
   **Resposta correta:** D  
   **Feedback:** O F1-Score é uma métrica crucial quando lidamos com conjuntos de dados desbalanceados, pois equilibra a precisão e o recall. Esta pergunta avalia se o aluno entende a importância de usar métricas apropriadas em diferentes contextos de dados.

3. **O que representa a precisão em um modelo de classificação?**  
   **Resposta correta:** A  
   **Feedback:** A precisão mede a proporção de verdadeiros positivos entre todas as predições positivas feitas pelo modelo. Entender a precisão é vital para avaliar como um modelo se comporta em termos de falsos positivos.

4. **Qual métrica mede a capacidade do modelo de identificar corretamente as instâncias da classe positiva?**  
   **Resposta correta:** B  
   **Feedback:** O recall, ou sensibilidade, é importante para avaliar a capacidade do modelo de detectar corretamente as instâncias da classe positiva, sendo fundamental em situações onde as falhas de detecção de uma classe específica têm consequências graves.

5. **Qual é a principal limitação da acurácia em modelos de classificação?**  
   **Resposta correta:** B  
   **Feedback:** Embora seja uma métrica simples e intuitiva, a acurácia pode ser enganosa, especialmente em conjuntos de dados desbalanceados. É importante que os alunos compreendam suas limitações para evitar conclusões incorretas sobre o desempenho do modelo.

6. **O que é o F1-Score?**  
   **Resposta correta:** B  
   **Feedback:** O F1-Score é a média harmônica da precisão e recall, sendo particularmente útil quando há um desequilíbrio entre as classes. Esta pergunta reforça o conceito de combinar múltiplas métricas para obter uma visão mais equilibrada do desempenho do modelo.

7. **Qual métrica é representada pelo número de verdadeiros positivos divididos pelo número total de positivos reais?**  
   **Resposta correta:** B  
   **Feedback:** Esta é a definição de recall. Compreender o recall é crucial para avaliar a capacidade do modelo de capturar todas as instâncias positivas, evitando falsos negativos.

8. **Em uma matriz de confusão, o que representam os valores na diagonal principal?**  
   **Resposta correta:** B  
   **Feedback:** Os valores na diagonal principal representam as predições corretas, tanto para positivos quanto para negativos. Essa pergunta verifica se o aluno entende a estrutura da matriz de confusão.

9. **Qual das seguintes métricas combina a precisão e o recall em uma única métrica de desempenho?**  
   **Resposta correta:** C  
   **Feedback:** O F1-Score é uma métrica combinada que ajuda a avaliar o modelo de forma mais equilibrada quando se lida com classes desbalanceadas, uma noção essencial para o entendimento holístico do desempenho do modelo.

10. **Quando um modelo tem alta precisão, mas baixo recall, ele está:**  
    **Resposta correta:** D  
    **Feedback:** Esta situação ocorre quando o modelo é muito conservador em suas predições positivas, resultando em poucos falsos positivos, mas muitos falsos negativos. É importante que os alunos entendam as implicações de ajustar os trade-offs entre precisão e recall.
	
	